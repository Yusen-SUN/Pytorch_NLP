{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import sentencepiece as spm\n",
    "\n",
    "\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from word2vector import Vocab\n",
    "from EncoderRNN import EncoderRNN\n",
    "from Attention import Attn\n",
    "from DecoderRNN import DecoderRNN\n",
    "from Data_reading import input_data\n",
    "from Pretrained_embedding import pre_embedding\n",
    "import Train\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove = pre_embedding('glove')\n",
    "# Glove.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(Glove)==None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_train, src_train_lens, tgt_train, src_val, src_val_lens, tgt_val = Data_reading.input_data(Glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_user = spm.SentencePieceProcessor()\n",
    "sp_user.load('m.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_train (99065, 50)\n",
      "src_train_lens (99065,)\n",
      "tgt_train (99065, 50)\n",
      "tgt_train_lens (99065,)\n",
      "src_val (4959, 50)\n",
      "src_val_lens (4959,)\n",
      "tgt_val (4959, 50)\n",
      "tgt_val_lens (4959,)\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 50\n",
    "src_train, src_train_lens, tgt_train, tgt_train_lens, src_val, src_val_lens, tgt_val, tgt_val_lens =  input_data(sp_user, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(src_train_lens, np.max(src_train_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(tgt_train_lens[tgt_train_lens<100], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(src_val_lens, np.max(src_val_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(tgt_val_lens, np.max(tgt_val_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.arange(5000)\n",
    "formal_train_tensors = torch.LongTensor(src_train[test]).to(device)\n",
    "formal_train_lens_tensors = torch.LongTensor(src_train_lens[test]).to(device)\n",
    "informal_train_tensors = torch.LongTensor(tgt_train[test]).to(device)\n",
    "informal_train_lens_tensors = torch.LongTensor(tgt_train_lens[test]).to(device)\n",
    "\n",
    "test_1= np.arange(1000)\n",
    "formal_val_tensors = torch.LongTensor(src_val[test_1]).to(device)\n",
    "formal_val_lens_tensors = torch.LongTensor(src_val_lens[test_1]).to(device)\n",
    "informal_val_tensors = torch.LongTensor(tgt_val[test_1]).to(device)\n",
    "informal_val_lens_tensors = torch.LongTensor(tgt_val_lens[test_1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "num_layer = 3\n",
    "dropout = 0.3\n",
    "hidden_dim = 128\n",
    "batch_size = 64\n",
    "learning_rate=0.001\n",
    "vocab_size = sp_user.get_piece_size() #len(Glove.word2index)\n",
    "#embedding=None\n",
    "attn = 'general'\n",
    "style_1 = sp_user.piece_to_id('<informal>')\n",
    "style_2 = sp_user.piece_to_id('<formal>')\n",
    "\n",
    "encoder = EncoderRNN(vocab_size=vocab_size, embedding_dim=embedding_dim, hidden_dim=hidden_dim, device=device ,\n",
    "                     num_layer=num_layer, dropout=dropout).to(device)\n",
    "\n",
    "decoder = DecoderRNN(attn_model=attn, vocab_size=vocab_size, embedding_dim=embedding_dim, \n",
    "                     hidden_dim=hidden_dim, device=device , num_layer=num_layer, dropout=dropout).to(device)\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(),lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1\n",
      "4992/5000, loss:16.255701065063477\n",
      "Evalidation: 960/1000, loss:14.388430786132812\n",
      "\n",
      "0m 51s (- 42m 3s) train loss: 15.200.  val loss: 11.827.\n",
      "val loss decreases from 100.000 to 11.827, save models\n",
      "\n",
      "iter 2\n",
      "4992/5000, loss:14.203097343444824\n",
      "Evalidation: 960/1000, loss:13.563751220703125\n",
      "\n",
      "1m 43s (- 41m 31s) train loss: 11.012.  val loss: 11.113.\n",
      "val loss decreases from 11.827 to 11.113, save models\n",
      "\n",
      "iter 3\n",
      "4992/5000, loss:15.737770080566406\n",
      "Evalidation: 960/1000, loss:13.445114135742188\n",
      "\n",
      "2m 36s (- 40m 46s) train loss: 10.687.  val loss: 11.038.\n",
      "val loss decreases from 11.113 to 11.038, save models\n",
      "\n",
      "iter 4\n",
      "4992/5000, loss:16.356111526489258\n",
      "Evalidation: 960/1000, loss:13.354389953613282\n",
      "\n",
      "3m 27s (- 39m 49s) train loss: 10.702.  val loss: 10.973.\n",
      "val loss decreases from 11.038 to 10.973, save models\n",
      "\n",
      "iter 5\n",
      "4992/5000, loss:14.836542129516602\n",
      "Evalidation: 960/1000, loss:13.280160522460937\n",
      "\n",
      "4m 19s (- 38m 52s) train loss: 10.751.  val loss: 10.869.\n",
      "val loss decreases from 10.973 to 10.869, save models\n",
      "\n",
      "iter 6\n",
      "4992/5000, loss:13.799073219299316\n",
      "Evalidation: 960/1000, loss:13.323812866210938\n",
      "\n",
      "5m 11s (- 38m 6s) train loss: 10.521.  val loss: 10.925.\n",
      "\n",
      "iter 7\n",
      "4992/5000, loss:13.485776901245117\n",
      "Evalidation: 960/1000, loss:13.217860412597656\n",
      "\n",
      "6m 2s (- 37m 9s) train loss: 10.659.  val loss: 10.825.\n",
      "val loss decreases from 10.869 to 10.825, save models\n",
      "\n",
      "iter 8\n",
      "4992/5000, loss:12.335860252380371\n",
      "Evalidation: 960/1000, loss:13.259239196777344\n",
      "\n",
      "6m 54s (- 36m 15s) train loss: 10.585.  val loss: 10.841.\n",
      "\n",
      "iter 9\n",
      "4672/5000, loss:10.68159008026123"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e9e050697530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mstyle_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstyle_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstyle_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             epoches=50, batch_size=batch_size, print_every=1, plot_every=1)\n\u001b[0m",
      "\u001b[0;32m~/nlp_github/machine_translation/unsupervised_cross_align/Train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(tensors_1, input_lengths_1, tensors_2, input_lengths_2, tensors_1_val, input_lengths_1_val, tensors_2_val, input_lengths_2_val, style_1, style_2, encoder, decoder, encoder_optimizer, decoder_optimizer, epoches, batch_size, print_every, plot_every, patience, decay_rate, early_stop)\u001b[0m\n\u001b[1;32m    217\u001b[0m         train_loss = trainEpoch(tensors_1, input_lengths_1, tensors_2, input_lengths_2, style_1, style_2, \n\u001b[1;32m    218\u001b[0m                                 \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                                 epoches, batch_size)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors_1_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths_1_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors_2_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths_2_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlp_github/machine_translation/unsupervised_cross_align/Train.py\u001b[0m in \u001b[0;36mtrainEpoch\u001b[0;34m(tensor_1, input_length_1, tensor_2, input_length_2, style_1, style_2, encoder, decoder, encoder_optimizer, decoder_optimizer, epoches, batch_size)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         loss = trainBatch(tensors_1, input_lengths_1, tensors_2, input_lengths_2, style_1, style_2, \n\u001b[0;32m--> 138\u001b[0;31m                           encoder, decoder, 'train', encoder_optimizer, decoder_optimizer)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;31m#        loss = trainBatch(tensors_2, input_lengths_2, tensors_1, input_lengths_1, style_2, style_1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;31m#                          encoder, decoder, 'train', encoder_optimizer, decoder_optimizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlp_github/machine_translation/unsupervised_cross_align/Train.py\u001b[0m in \u001b[0;36mtrainBatch\u001b[0;34m(tensor_1, input_length_1, tensor_2, input_length_2, style_1, style_2, encoder, decoder, mode, encoder_optimizer, decoder_optimizer)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mrec_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/yusen/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/yusen/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Train.train(formal_train_tensors, formal_train_lens_tensors, informal_train_tensors, informal_train_lens_tensors,\n",
    "            formal_val_tensors, formal_val_lens_tensors, informal_val_tensors, informal_val_lens_tensors,\n",
    "            style_1=style_1, style_2=style_2,\n",
    "            encoder=encoder, decoder=decoder, encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer, \n",
    "            epoches=50, batch_size=batch_size, print_every=1, plot_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
